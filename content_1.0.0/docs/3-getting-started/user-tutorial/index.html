<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="UTF-8">
<title>SeqWare › User Tutorial</title>
<meta content="nanoc 3.6.2" name="generator">
<link href="../../../../assets/style-v17.css" media="screen" rel="stylesheet" type="text/css">
<link href="http://feeds.feedburner.com/seqware" rel="alternate" title="The SeqWare Blog" type="application/atom+xml">
<script type="text/javascript"> var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-34523087-1']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })(); </script>
</head>
<body>
<div class="wrapper">
<!-- ***** navigation ***** -->
<div class="nav">
<ol>
<li><a href="../../../../"><span>Home</span></a></li>
<li><a href="../../../../blog/"><span>News</span></a></li>
<li><a href="../../../../docs/"><span>Documentation</span></a></li>
<li><a href="../../../../community/"><span>Community</span></a></li>
<li><a href="../../../../partners/"><span>Partners</span></a></li>
<li><a href="../../../../about/"><span>About</span></a></li>
</ol>
</div>
<!-- ***** sidebar ***** -->
<div class="side">
<div class="section odd">
<script charset="utf-8" src="http://widgets.twimg.com/j/2/widget.js"></script><script> new TWTR.Widget({   version: 2,   type: 'profile',   rpp: 4,   interval: 30000,   width: 250,   height: 370,   theme: {     shell: {       background: '#daebff',       color: '#153b66'     },     tweets: {       background: '#daebff',       color: '#000000',       links: '#153b66'     }   },   features: {     scrollbar: false,     loop: false,     live: true,     behavior: 'all'   } }).render().setUser('seqware').start(); </script>
</div>
<div class="section even">
<p>The current version of SeqWare is 0.13.6.6, released on May 29th, 2013. See the <a href="../../../../release-notes/">release notes</a> for details.</p>
</div>
</div>
<!-- ***** body ***** -->
<div class="body">
<div class="article">
<div class="header">
<h1>User Tutorial</h1>
</div>
<div class="section" id="overview">
<h2>Overview</h2>

<p class="warning"><strong>Note:</strong>This guide assumes you have installed
SeqWare already. If you have not, please install SeqWare by either downloading
the VirtualBox VM or launching the AMI on the Amazon cloud.  See <a href="../../../../docs/2-installation/">Installation</a> for directions.</p>

<p>The majority of this guide is dedicated to walking users (people who use
workflows) through the basics of using SeqWare. The core functionality we will
explore is how to get data into the system, how to run workflows someone else
created and installed for you, and getting the resulting data back out.  We
assume that people are most interested in the Pipeline sub-project and focus
most of our time on that.  The examples below will all be based on a local
VirtualBox VM but the environment on our cloud instance is almost identical, so
most of the examples below will be applicable to either VM type. Any difference
will be pointed out in a tip box.</p>

</div>
<div class="section" id="by-the-end-of-this-tutorial">
<h2>By the End of This Tutorial</h2>

<p>This guide will show you how to use command line tools from Pipeline to access
the MetaDB via the Web Service in order to setup workflows to run in Pipeline,
watch over them, and get results back. This will allow you to do the following
tasks using tools that can be scripted versus our Portal web-based interface
that requires a user to click on an interface. By the end of these tutorials
you will be able to:</p>

<ul>
<li>use command line tools from Pipeline as a workflow user</li>
  <li>create studies, experiments, and samples in the MetaDB</li>
  <li>upload data such as fastq files to the VM and associate that data with particular samples in the MetaDB</li>
  <li>find the list of available workflows and the parameters they accept using Pipeline</li>
  <li>schedule a HelloWorld workflow and monitor its progress using Pipeline</li>
  <li>generate a report on the outputs of your workflows in Pipeline</li>
  <li>download files produced by a workflow using Pipeline tools</li>
  <li>debug workflows by downloading stdout and stderr for your workflows</li>
</ul>
<p>The command line tools are all Java tools from SeqWare Pipeline that wrap our
RESTful SeqWare Web Service. If you would like to learn more about the
low-level API (perhaps you want to call it directly in a program or script) you
can find more information in the <a href="../../../../docs/7-web-service/">SeqWare Web Service</a>
documentation.</p>

<p class="warning"><strong>Tip:</strong>If you want to see how to do the same
steps covered in this tutorial via the Portal web GUI instead of command line
tools see the <a href="../../../../docs/5-portal/user-guide/">Portal User Guide</a>.</p>

</div>
<div class="section" id="first-steps">
<h2>First Steps</h2>

<p>Please launch your local VM in VirtualBox or cloud AMI on Amazon now.  For the
local VM, login as user <kbd>seqware</kbd>, password <kbd>seqware</kbd> at this
time. Click on the “SeqWare Directory” link on the desktop which will open a
terminal to the location where we installed the SeqWare tools.</p>

<p>Alternatively, on the Amazon AMI follow the directions to log in
<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AccessingInstancesLinux.html">here</a>.
Make sure that you launch our VM with the “cc1.4xlarge” instance type.
Also, please wait roughly 10 minutes for our startup scripts to run and fully setup your instance. You can verify whether the scripts have completed by looking for a touch file.</p>

<pre><code>cat /tmp/seqware_setup_ran 
date
</code></pre>

<p>The date command shows the current time, the cat command shows you when the setup script finished running.</p>

<p>Once logging into the remote instance you need to “switch user” to
<kbd>seqware</kbd>, e.g.:</p>

<pre><code>    sudo su - seqware
</code></pre>

<p>Both the VirtualBox VM and Amazon AMI include a start page that links to key information
for the VM such as the URLs for the installed Portal, Web Service, key file locations, etc.
On the VirtualBox VM, just click the “Start Here” link on the desktop.  For the Amazon instance
use the instance name provided by the AWS console. For example, it will look similar to:</p>

<pre><code>http://ec2-54-224-22-195.compute-1.amazonaws.com
</code></pre>

<p>You fill in your instance DNS name from the Amazon console in place of ec2-54-224-22-195.compute-1.amazonaws.com above.</p>

</div>
<div class="section" id="the-example">
<h2>The Example</h2>

<p>In this tutorial we will use a simple HelloWorld workflow that takes a text
file as input and creates another file as output. The same examples could be
applied to any workflow and input data types.  How to build your own workflows
(<strong>which is really the central purpose of SeqWare</strong>) is covered in the
<a href="../../../../docs/3-getting-started/developer-tutorial/">Developer Tutorial</a>. How to
install these workflows and present them to users is covered in the <a href="../../../../docs/3-getting-started/admin-tutorial/">Admin
Tutorial</a>.</p>

<p class="warning"><strong>Cloud Tip:</strong>Any differences between the local
VirtualBox VM and Amazon cloud AMI will be described in a &#8220;Cloud Tip&#8221; box like
this one.</p>

</div>
<div class="section" id="the-seqware-command-line-tool">
<h2>The SeqWare Command Line Tool</h2>

<p>SeqWare is an open source software project built mostly in Java. In the seqware
user’s home directory (<kbd>/home/seqware/</kbd>) you will see a SeqWare jar
file (<kbd>seqware-distribution-0.13.6.5-full.jar</kbd>).
This jar is, essentially, the command line interface for the whole SeqWare
project. It contains the SeqWare Pipeline code that will allow you to interact
with the SeqWare Web service (whether it is on a VM, installed on another local
machine/cluster, or in the cloud) that controls, among other things, workflow
execution. </p>

<p class="warning"><strong>Tip:</strong>If you are using a development release
of the AMI/VM or have downloaded SeqWare source from git and compiled the
version number in the jar and sample commands throughout these guides will be
different. Please substitute the current release string in the commands you see
throughout this guide.</p>

<p>In the image below you get a glimpse of how these SeqWare tools fit together.
For users of the SeqWare system the command line tools, Web Service, or web
Portal application all provide access to the lifecycle of workflow usage. This
includes finding the workflows that are available, seeing what parameters they
take, launching a workflow on specified inputs/parameters, monitoring the
status, debugging the output if something goes wrong, and getting results back.
This process is pretty much identical whether SeqWare is installed locally on a
VirtualBox VM, running on a self-contained cloud instances, or a production
installation running on a real HPC cluster. In the image below the “Amazon S3”
and “Amazon EC2” components can be substituted with a shared NFS fileserver and
HPC cluster like a Sun Grid Engine cluster if SeqWare is used on a local,
non-cloud infrastructure. Likewise, the whole setup would be installed on a
single box if using a VirtualBox VM.</p>

<p><img src="../../../../assets/images/seqware_tool_interaction.png" width="600px"></p>

<p>For more information about the command line tools see the
<a href="../../../../docs/17-plugins/">Plugin</a> and <a href="../../../../docs/17a-modules/">Modules</a> references which
gives the usage for all our command line utilities.</p>

<p class="warning"><strong>Tip:</strong> The VM will contain a recent version
of the jar that we have validated with this tutorial.  You may want to upgrade
to the latest version, though, which you can download from our <a href="http://jenkins.res.oicr.on.ca/job/seqware/">continuous build server</a>.
Please choose the jar that has the -full suffix, e.g.
seqware-distribution-0.13.6-full.jar. Keep in mind we make no promises that the
latest version will be bug free!</p>

</div>
<div class="section" id="the-seqware-settings-file">
<h2>The SeqWare Settings File</h2>

<p>The SeqWare jar file uses a simple configuration file that has been setup for
you already on the VM. By default the location is ~/.seqware/settings.</p>

<p>This file contains the web address of the SeqWare Web Service, your username
and password, and you Amazon public and private keys that will allow you to
push and pull data files to and from the cloud, etc. For this tutorial the
config file should be ready to go, you will not need to modify it.</p>

<p>For more information see the <a href="../../../../docs/6-pipeline/user-configuration/">Settings</a>
documentation which covers the details on the user config file.</p>

</div>
<div class="section" id="creating-studies-experiments-and-samples">
<h2>Creating Studies, Experiments, and Samples</h2>

<p>This tutorial starts with setting up study, experiment, and sample metadata in
the SeqWare MetaDB.  SeqWare MetaDB lets you track studies, experiment, and
samples and then link those to files (like FASTQ or something similar). You can
then run workflows on those files, track the resulting files, and use those
files for the next workflow.</p>

<p>You can run workflows without metadata writeback to the MetaDB but most users
will want to associate a run of a workflow with a particular sample so that is
why we start with setting up this information.  You will want to set up your
study, experiments, and samples before uploading your text or other data files.
This ensures you have “parents” to attach these files to.  Otherwise you will
not be able to use them as parameters for workflows. </p>

<p>The functionality for each of these metadata tools described below is fairly
limited.  For example, the rich descriptive “Spot Decoding String” language for
describing how a read is structured is not yet fully supported and updates to
existing entities are not yet possible. That is functionality we hope to add in
future releases.  However the basic functionality to create studies,
experiments, and samples now exists in a scriptable form and that is really the
point.  By providing command line tools you can automate the setup of this
information using simple Bash shell scripts or the language of your choice.</p>

<p class="warning"><strong>Tip:</strong>You can use SeqWare Portal to edit the
entries you make with the command line tools (or create more studies,
experiments, and samples). See the <a href="../../../../docs/5-portal/user-guide/">Portal
User Guide</a> for more information.</p>

<p>First, you can find out what tables this tool is capable of writing to:</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.Metadata -- --list-tables

TableName

study
experiment
sample
sequencer_run
ius	
lane
</code></pre>

<p>Now, for a given table, you can find out what fields you can write back to and their type:</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.Metadata -- --table study --list-fields

Field    Type    Possible_Values
title    String
description    String
accession    String
center_name    String
center_project_name    String
study_type    Integer    [1: Whole Genome Sequencing, 2: Metagenomics, 3: Transcriptome Analysis, 4: Resequencing, 5: Epigenetics, 6: Synthetic Genomics, 7: Forensic or Paleo-genomics, 8: Gene Regulation Study, 9: Cancer Genomics, 10: Population Genomics, 11: Other]
</code></pre>

<p>So using the information above you can create a new study:</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.Metadata -- --table study --create --field 'title::New Test Study' --field 'description::This is a test description' --field 'accession::InternalID123' --field 'center_name::SeqWare' --field 'center_project_name::SeqWare Test Project' --field study_type::4

SWID: 2
</code></pre>

<p>The output of this command above includes the line “SWID: 2” (or whatever
number is appropriate for your database).  This is very important since this
number is a unique identifier across the database and used to link together
entities.  For example, you will use the number produced by the study add
command as the parent for the experiment you create below.  If you do not track
and supply these numbers then the hierarchy of study/experiment/sample cannot
be created.</p>

<p>The next step is to create an experiment and link it to the study you created
above. You can find the platform ID using the <tt>–list-fields</tt> option shown above:</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.Metadata -- --table experiment --create --field 'title::New Test Experiment' --field 'description::This is a test description' --field platform_id::26 --field study_accession::2

SWID: 3 
</code></pre>

<p>Again, you use the SWID from the above output in the next step to create an
associated sample. You can find the platform ID using the <tt>–list-fields</tt> option
shown above:</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.Metadata -- --table sample --create --field 'title::New Test Sample' --field 'description::This is a test description' --field organism_id::26 --field experiment_accession::3

SWID: 4
</code></pre>

<p>At this point you should have a nice study/experiment/sample hierarchy.  You
can, of course, add multiple samples per experiment and multiple experiments
per study.  For each of the samples you can now upload one or more files.  You
will need the SWID from the sample creation above for this step (or visible in
the Portal).  Here is a screenshot of what the above commands produce in the
<a href="../../../../docs/5-portal/">Portal</a> (note, the SWIDs do not match but these are just examples):</p>

<p><img src="../../../../assets/images/final_exp.png" width="600px"></p>

</div>
<div class="section" id="uploading-files-and-associating-with-a-sample">
<h2>Uploading Files and Associating with a Sample</h2>

<p>The first step in uploading a file and associating with a sample is to identify
the sample’s SWID. Once you
decide on the “parent” sample to attach the file to you then need to know the
destination location to put your file in.  For the local VM this is either a
directory (which defaults to <kbd>/datastore</kbd>) or a shared filesystem over
NFS if you have connected your VM instance to shared storage and a cluster.
The default <kbd>/datastore</kbd> will work fine here on this single,
self-contained VM instance (either the VirtualBox VM or Amazon AMI).</p>

<p>Once you have these two pieces of information (destination path “/datastore/”
and the sample SWID) you can then use the command line utilities
(ProvisionFiles or GenericMetadataSaver) to put your files into the right place
and associate them with the correct sample.</p>

<div class="section" id="creating-a-helloworld-text-file">
<h3>Creating a HelloWorld Text File</h3>

<p>Moving on with the HelloWorld example workflow, you will now need to create an input text
file to associate with the sample created previously. This will be the input file for the
HelloWorld workflow.  For example, do the following in your home directory:</p>

<pre><code>echo 'testing HelloWorld' &gt; ~/input.txt
</code></pre>

</div>
<div class="section" id="associating-uploaded-files-with-a-sample">
<h3>Associating Uploaded Files with a Sample</h3>

<p>Here is an example of calling the ProvisionFiles command line utility which
will copy a file (<tt>~/input.txt</tt>) to a destination (<tt>/datastore/</tt>)
and also update the database to link the parent sample (SWID:4 above) to
the newly copied file that has the final path <tt>/datastore/input.txt</tt>:</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.ModuleRunner -- --module net.sourceforge.seqware.pipeline.modules.utilities.ProvisionFiles --metadata-output-file-prefix /datastore/ --metadata-processing-accession-file accession.txt --metadata-parent-accession 4 -- -im text::text/plain::/home/seqware/input.txt -o /datastore/ --force-copy 
</code></pre>

<p>In this example it will copy the /home/seqware/input.txt text file to
/datastore/ directory (which we are using for this tutorial) and will link it 
to the sample identified by 4 (the sample’s SWID).  So the final output
file is “/datastore/input.txt” in the database. If you left off –force-copy
you would get a symlink in this case since it is a local file operation.  If
you left off “–metadata-output-file-prefix /datastore/” then the file path in
the DB would just be “input.txt”. The parameter
“–metadata-processing-accession-file accession.txt” will cause the SWID for
the ProvisionFiles event to be written to the accession.txt file. Take a look
at the accession for the ProvisionFiles event now, you will use this value as
the parent for the actual run of the HelloWorld workflow:</p>

<pre><code>cat /home/seqware/accession.txt
5	
</code></pre>

<p>In this case the SWID for the ProvisionFiles is 5.</p>

<p class="warning"><strong>Tip:</strong> you can find a list of the meta types
(like chemical/seq-na-text-gzip or text/plain above) at <a href="http://seqware.github.io/docs/16-module-conventions/">Module
Conventions - Module MIME Types</a>. This is the list we add to as needed when
creating new workflows.  It is extremely important to be consistent with these
since a workflow will not recognize your input unless the meta type string
matches what it expects exactly.</p>

</div>
<div class="section" id="associating-existing-files-with-a-sample">
<h3>Associating Existing Files with a Sample</h3>

<p>The ProvisionFiles utility above both uploads/copies the input file and also
saves the metadata back to the database.  However, sometimes you have already
uploaded data or, as is the case for the local VM, it is a single filesystem so
there is no reason to make copies of the data (the same would be true if
/home/seqware/ was on an NFS share on a cluster for example).  In this case you
just want to link the files to particular samples in the database.
GenericMetadataSaver is the tool you can use to accomplish this, for example,
if you already had input2.txt in /datastore you could insert this into the
MetaDB using:</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.ModuleRunner -- --module net.sourceforge.seqware.pipeline.modules.GenericMetadataSaver --metadata-parent-accession 4 --metadata-processing-accession-file accession2.txt -- --gms-output-file text::text/plain::/datastore/input2.txt --gms-algorithm UploadText --gms-suppress-output-file-check
</code></pre>

<p>Here files are associated with the parent (SWID: 4 which is a sample). 
Also, the file accession2.txt contains the SWID for this /datastore/input2.txt file.</p>

<pre><code>cat /home/seqware/accession2.txt
</code></pre>

<p>One word of caution, if you expect people to download your files through the
Portal then the paths you inject into the database must be in a place where the
Portal can “see” it. See the <a href="../../../../docs/5-portal/">Portal documentation</a> for
information on setting the shared directory it expects to find uploaded files
in.  For the VM, this is /datastore/.</p>

</div>
</div>
<div class="section" id="listing-available-workflows-and-their-parameters">
<h2>Listing Available Workflows and Their Parameters</h2>

<p>Once you have uploaded data the next step is to find the available workflows
and their parameters.  To see the list of available workflows you can execute
the following command:</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.BundleManager -- --list-install
java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.BundleManager -- --list-install --human-aligned
java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.BundleManager -- --list-install --human-expanded
</code></pre>

<p>First, you will get a tab-delimited list of workflows showing their name, version, and 
(most importantly) their SWID that you can use in scripts. In the second and third examples
, you will get a more user-friendly versions of the output. </p>

<p>In this example we are going to use the latest (at the time of this writing)
HelloWorld workflow bundle (SWID 1 below).  The output of the above command
includes:</p>

<pre><code>-[ RECORD 0 ]----+--------------------------------------------------------------------------------------------
Name             | HelloWorld                                                                                  
Version          | 1.0-SNAPSHOT                                                                                
Creation Date    | Thu Apr 18 11:30:52 PDT 2013                                                                
SeqWare Accession| 1                                                                                           
Bundle Location  | /home/seqware/released-bundles/Workflow_Bundle_HelloWorld_1.0-SNAPSHOT_SeqWare_0.13.6.5.zip 
</code></pre>

<p>The fourth column includes the SWID for this workflow that you will use in the
next command to find all the parameters (and their defaults) that this workflow
takes.  Here is the command, notice we redirect the output to create a basic ini
file that can later be customized and used to submit a run of this workflow:</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.BundleManager -- --list-workflow-params --workflow-accession 1 &gt; /home/seqware/workflow.ini
</code></pre>

<p>In this example the workflow “HelloWorld” version 1.0 (SWID 1)
parameters are listed.  The output conforms to the input you can use to
parameterize and launch workflows.  For example:</p>

<pre><code>#key=input_file:type=file:display=F:display_name=input_file:file_meta_type=text/plain
input_file=${workflow_bundle_dir}/Workflow_Bundle_helloworld/1.0/data/input.txt
#key=output_dir:type=text:display=F:display_name=output_dir
output_dir=seqware-results
#key=output_prefix:type=text:display=F:display_name=output_prefix
output_prefix=./
</code></pre>

<p class="warning"><strong>Important!:</strong> the lines above have been
wrapped but you should not include line breaks in your file.  Instead, make
sure the file that you create using this tool (and customize for later
launching a workflow) includes comment lines starting with “#” and the
key=value lines only.  In the command above the redirect to the file
workflow.ini will include some extra lines of status output.  Make sure you
remove these before continuing to launch the workflow with this ini file.</p>

<p>You can customize any values from the key/value pairs that you need to.  For
example, the most frequent parameters you will customize are input files.  In
the workflow example above you will want to customize <tt>input_file</tt> (set
it to the location of the file you uploaded) and the <tt>output_prefix</tt>
(set it to the common shared directory we use on this VM/AMI
<tt>/datastore/</tt>). For example:</p>

<pre><code>input_file=/datastore/input.txt
output_prefix=/datastore/
</code></pre>

<p>Since this is a low-level tool you may see many more parameters exposed with
this tool than you would using the web Portal application.  Please use caution
when customizing these values since some refer to items that affect the
underlying infrastructure. Generally, when you see <tt>display=F</tt> that is
an indication that the parameter should usually be left as the default value.</p>

<p class="warning"><strong>Tip:</strong> when you customize key-values in the
ini file prepared above you do not need to include key-values that you leave
unchanged.  If you do not include these the workflow will run with those values
by default anyway.  Removing unchanged key-values will greatly reduce the size
of your ini files making it much easier to see the key-values you are
interested in. In the example above the minimal ini file is simply the two
lines for <tt>input_file</tt> and <tt>output_prefix</tt>.</p>

<p>In summary, your should edit the workflow.ini changing it from:</p>

<pre><code>Running Plugin: net.sourceforge.seqware.pipeline.plugins.BundleManager
Setting Up Plugin: net.sourceforge.seqware.pipeline.plugins.BundleManager@16ba8602
=====================================================
=================WORKFLOW PARAMS=====================
=====================================================
-----------------------------------------------------
#key=input_file:type=file:display=F:display_name=input_file:file_meta_type=text/plain
input_file=${workflow_bundle_dir}/Workflow_Bundle_HelloWorld/1.0-SNAPSHOT/data/input.txt
#key=greeting:type=text:display=T:display_name=Greeting
greeting=Testing
#key=output_dir:type=text:display=F:display_name=output_dir
output_dir=seqware-results
#key=output_prefix:type=text:display=F:display_name=output_prefix
output_prefix=./

-----------------------------------------------------
</code></pre>

<p>to the following:</p>

<pre><code>#key=input_file:type=file:display=F:display_name=input_file:file_meta_type=text/plain
input_file=/datastore/input.txt
#key=greeting:type=text:display=T:display_name=Greeting
greeting=Testing
#key=output_dir:type=text:display=F:display_name=output_dir
output_dir=seqware-results
#key=output_prefix:type=text:display=F:display_name=output_prefix
output_prefix=/datastore/
</code></pre>

</div>
<div class="section" id="triggering-a-workflow-and-monitoring-progress">
<h2>Triggering a Workflow and Monitoring Progress</h2>

<p>At this point you know what workflow you are going to run and you have a
customized ini file that contains the <tt>input_file</tt> and
<tt>output_prefix</tt>. The next step is to launch the workflow using the ini
file you prepared. Make sure you use the correct workflow accession and parent
accession. The former was listed when you listed all workflows (SWID:1 in this
example) and the latter was printed to the <tt>accession.txt</tt> file when you
copied the file using ProvisionFile (SWID:5 in this example).</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.WorkflowLauncher -- --ini-files /home/seqware/workflow.ini --workflow-accession 1 --schedule --parent-accessions 5 --host `hostname --long` 
WORKFLOW_RUN ACCESSION: 11
</code></pre>

<p class="warning"><strong>Tip:</strong> the parent-accessions is the SWID of
the ProvisionFiles element that was added under the sample when use used this
tool to upload the text files in the example above.  You MUST specify this
otherwise the workflow&#8217;s results will not be linked to anything (they will be
orphaned and will not be visible in the Portal or present in the reports
below). Conveniently the ProvisionFiles tool will write these accessions to a
file and the portal displays these values.</p>

<p>This schedules the workflow to run on the VM. Notice it also prints the
workflow run accession which you can use to help monitor the workflow.</p>

<p>You can then monitor workflow progress (and getting a list of the outputs)
using the WorkflowRunReporter plugin. This will let you script the monitoring
of workflow runs.</p>

<pre><code>[seqware@master ~]$ java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.WorkflowRunReporter -- --workflow-accession 1 --stdout --human
Running Plugin: net.sourceforge.seqware.pipeline.plugins.WorkflowRunReporter
Setting Up Plugin: net.sourceforge.seqware.pipeline.plugins.WorkflowRunReporter@744a6cbf
Apr 24, 2013 9:12:40 AM org.restlet.ext.httpclient.HttpClientHelper start
INFO: Starting the Apache HTTP client
-[ RECORD 0 ]----------------+-------------------------------------------------------------------------------
Workflow                     | HelloWorld 1.0-SNAPSHOT                                                        
Workflow Run SWID            | 11                                                                             
Workflow Run Status          | running                                                                        
Workflow Run Create Timestamp| 2013-04-24 09:09:59.77                                                         
Workflow Run Host            | master                                                                         
Workflow Run Status Command  | pegasus-status -l /home/seqware/pegasus-dax/seqware/pegasus/HelloWorld/run0002 
Library Sample Names         |                                                                                
Library Sample SWIDs         |                                                                                
Identity Sample Names        | New Test Sample                                                                
Identity Sample SWIDs        | 4                                                                              
Input File Meta-Types        | text/plain                                                                     
Input File SWIDs             | 7                                                                              
Input File Paths             | /datastore/input.txt                                                           
Output File Meta-Types       |                                                                                
Output File SWIDs            |                                                                                
Output File Paths            |                                                                                
Workflow Run Time            | 0 ms   
</code></pre>

<p>This output includes several columns of interest including the status of the
workflow, the output file types, and their locations in S3 or the file system.
If you omit the <tt>–human</tt> option, you can get tabbed output to automate 
the checking of workflows and the
retrieval of the results! You can skip writing to an output
file by just using the <tt>–stdout</tt> option which is helpful if you are scripting
on top of this command. </p>

<p>After about ten minutes, the workflow should complete. </p>

<p>Alternatively, you can just get the status of a particular workflow run, for
example, the workflow run accession printed when you launched the workflow with
the WorkflowLauncher(for example SWID: 11).  </p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.WorkflowRunReporter -- --workflow-run-accession 11 --stdout
</code></pre>

<p>In the output from the above command you will see accessions for each workflow
run. If the status is “failed” you can download the stderr and stdout from the
workflow run. This is how you might do that for our workflow_run with an
accession of SWID: 11 (Note that there is no useful output in our tutorial after the 
workflow completes successfully):</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.WorkflowRunReporter -- --wra 11 --wr-stderr
java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.WorkflowRunReporter -- --wra 11 --wr-stdout
</code></pre>

<p>Again, this command automatically creates output files for stderr and stdout,
for example <tt>20130414<em>202120__workflowrun</em>11_STDERR.csv</tt>.  You can
use the <tt>–stdout</tt> option if you wish to skip the output file and just
write to the terminal.</p>

</div>
<div class="section" id="the-resulting-structure-in-metadb">
<h2>The Resulting Structure in MetaDB</h2>

<p>After a few minutes the HelloWorld workflow you just launched should be
complete with a status of “completed”.  If you have followed the directions
carefully for creating a study, experiment, and sample in the MetaDB, uploading
an input file with ProvisionFile, and running a workflow you should have a
structure very similar to the following present in the MetaDB:</p>

<p><img src="../../../../assets/images/20130414_sample_workflow_run.png" width="600px"></p>

<p>You can see the study, experiment, and sample linked together along with
a processing event (ProvisionFiles) attached directly to the sample. This
event is associated with the <tt>input.txt</tt> file and it is the parent
of the first step in the HelloWorld workflow run. This workflow run
has three steps in this example and the final step is associated to the 
output file <tt>output.txt</tt>.  The processing event for Step3 could
then go on to become the parent for a subsequent workflow.</p>

<p>For a more detailed explination of the SeqWare MetaDB and the relationships it
encodes please see the <a href="../../../../docs/4-metadb/">MetaDB Documentation</a>. You can use
either the <a href="../../../../docs/5-portal/">Portal</a> or various reporting tools available in
the <a href="../../../../docs/6-pipeline/">Pipeline</a> and/or <a href="../../../../docs/7-web-service/">Web Service</a> to
explore the data structures and files created when running workflows.</p>

</div>
<div class="section" id="downloading-workflow-results">
<h2>Downloading Workflow Results</h2>

<p>Once a workflow has finished running you will want to list out the associated
output files and download the results.  While you can use the Portal for
downloading files the best way to get files in bulk is to use our reporting
tool. This produces a tab-delimited file that lists all the files produced for
the workflows you are interested in.  You can then use the same ProvisionFiles
utility above to pull files back.  Since the report produces a simple
tab-delimited file you can easily automate the downloading of results by
looping over the output files and calling ProvisionFiles using a script.</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.SymLinkFileReporter -- --no-links --output-filename study_report --workflow-accession 1 --study 'New Test Study'
java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.SymLinkFileReporter -- --no-links --output-filename study_report --workflow-accession 1 --study 'New Test Study' --human --stdout
</code></pre>

<p>In the first case, the output is a <tt>study_report.csv</tt> file that contains a line for
each file output for this workflow.
In the second case, the output is a more user-friendly output intended for viewing on the command-line.
  You can also filter by file types, for
example if you want to see just plain text files:</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.SymLinkFileReporter -- --no-links --output-filename study_report --workflow-accession 1 --study 'New Test Study' --file-type 'text/plain'
</code></pre>

<p>Or an example filtering by a particular sample:</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.SymLinkFileReporter -- --no-links --output-filename study_report --workflow-accession 1  --sample 'New Test Sample'
</code></pre>

<p>You can use these output file URLs (such as
s3://bucket/samplename/test_R1.text.gz) with ProvisionFiles to download results
if they are remote. In the local VM they are just local files so they do not
need to be copied.  Here is an example, though, of how to download a report
bundle that is hosted on Amazon’s S3:</p>

<pre><code>java -jar ~/seqware-distribution-0.13.6.5-full.jar -p net.sourceforge.seqware.pipeline.plugins.ModuleRunner -- --module net.sourceforge.seqware.pipeline.modules.utilities.ProvisionFiles --no-metadata -- -i s3://bucket/results/seqware-0.10.0_ComprehensiveExomeGenomeAnalysis-0.10.5/59491657/GAG.fa.variant_quality.gatk.hg19.report.zip -o /home/seqware/
</code></pre>

<p>Here the zip report bundle is downloaded to the seqware home directory.  In
this way you can pull back the results of workflows entirely through scripts
that wrap the SymLinkFileReporter and ProvisionFiles.</p>

<p>Also note the SymLinkFileReporter gives you SWIDs for processing events and
entities such as studies, samples, and experiments.  You can use this tool to
find these SWIDs that are used as “parents” for subsequent workflow runs.</p>

<p>You can find more information on this report tool on the <a href="../../../../docs/21-study-reporter/">Study
Reporter</a> page.</p>

<p class="warning"><strong>Note:</strong> in the example above I use
&#8211;no-metadata with ProvisionFiles. This is to prevent the tool from writing
back an event to the central database. Since you are just downloading a file
(versus uploading a file) you do not really want to record that download event
in the database.</p>

</div>
<div class="section" id="next-steps">
<h2>Next Steps</h2>

<p>See the <a href="../../../../docs/3-getting-started/developer-tutorial/">Developer Tutorial</a> for
how to create a new workflow.  How to install workflows and present them to
users is covered in the <a href="../../../../docs/3-getting-started/admin-tutorial/">Admin
Tutorial</a>.</p>
</div>
</div>
</div>
</div>
<!-- ***** footer ***** -->
<div id="footer">
<p>SeqWare © 2007–2013 Brian O&#8217;Connor. SeqWare is released under the a <a rel="license" href="http://www.gnu.org/licenses/licenses.html">GNU GPL v3</a>. This site is built using the excellent <a href="http://nanoc.ws/">nanoc</a> tool and example site along with the <a href="http://www.fonts.info/info/press/free-fonts-for-font-face-embedding.htm">Graublau</a> and <a href="https://en.wikipedia.org/wiki/Gentium">Gentium</a> fonts.</p>
</div>
</body>
</html>